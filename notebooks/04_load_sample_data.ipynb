{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from enum import Enum\n",
    "from sqlalchemy import create_engine, Table, Column, Integer, String, MetaData, ForeignKey, DateTime, Float\n",
    "from sqlalchemy.engine import URL, Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seting up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_JOB_TITLES = [\"data science\", \"data engineer\", \"data analyst\"]\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the .env file\n",
    "OER_API_KEY = os.getenv(\"OER_API_KEY\")\n",
    "REED_API_KEY = os.getenv('REED_USER')\n",
    "\n",
    "# Get the database connection settings from the .env file\n",
    "DB_USER = os.getenv(\"TEST_STAGING_DB_USERNAME\")\n",
    "DB_PASSWORD = os.getenv(\"TEST_STAGING_DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"TEST_STAGING_SERVER_NAME\")\n",
    "DB_PORT = os.getenv(\"TEST_STAGING_DB_PORT\")\n",
    "DB_NAME = os.getenv(\"TEST_STAGING_DB_NAME\")\n",
    "\n",
    "# Table names\n",
    "JOB_TABLE_NAME = \"job_advertisements\"\n",
    "EXCHANGE_TABLE_NAME = \"open_exchange_rates\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reed API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReedAPI:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.user = api_key\n",
    "        self.password = \"\"\n",
    "        self.base_url = \"https://www.reed.co.uk/api/1.0/search/\"\n",
    "        self.page_size = 50\n",
    "\n",
    "    def get_all_jobs(self, job_title: str) -> list[dict]:\n",
    "        jobs, total_results = self.get_jobs_partial(job_title, self.page_size, 0)\n",
    "        for page in range(1, total_results // self.page_size + 1):\n",
    "            time.sleep(1) # TODO Check the API rate limit\n",
    "            jobs.extend(self.get_jobs_partial(job_title, self.page_size, page)[0])\n",
    "\n",
    "            if page > 1: # TODO Remove this, it's just for testing\n",
    "                break\n",
    "        return jobs\n",
    "    \n",
    "    def get_jobs_partial(self, job_title: str, count: int, page: int) -> tuple[list[dict], int]:\n",
    "        print(f\"Getting jobs for {job_title} page {page}\")\n",
    "        params = {\n",
    "            \"keywords\" : job_title,\n",
    "            \"resultsToTake\" : count,\n",
    "            \"resultsToSkip\" : page * count\n",
    "        }\n",
    "        auth = HTTPBasicAuth(self.user, self.password)\n",
    "        response = requests.get(self.base_url, auth=auth, params=params)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(\"Failed to get jobs\")\n",
    "        response_json = response.json()\n",
    "        print(f\"Got {len(response_json.get('results'))} jobs for {job_title} page {page}. Total results: {response_json.get('totalResults')}\")\n",
    "        return (response_json.get(\"results\"), int(response_json.get(\"totalResults\")))\n",
    "    \n",
    "def reed_load(dict_list: list[dict]) -> pd.DataFrame:\n",
    "    df = pd.DataFrame(dict_list)\n",
    "    df_selected = df[['jobId', 'employerId','employerName', 'jobTitle', 'locationName', 'minimumSalary', 'maximumSalary', 'currency', 'date', 'applications', 'jobUrl']].copy()\n",
    "    df_selected['date'] = pd.to_datetime(df_selected['date'], format=\"%d/%m/%Y\", errors='coerce')\n",
    "    return df_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Exchange Rates API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Currency(Enum):\n",
    "    GBP = \"GBP\"\n",
    "    EUR = \"EUR\"\n",
    "    USD = \"USD\"\n",
    "    JPY = \"JPY\"\n",
    "    CHF = \"CHF\"\n",
    "    CAD = \"CAD\"\n",
    "    AUD = \"AUD\"\n",
    "    NZD = \"NZD\"\n",
    "    ZAR = \"ZAR\"\n",
    "    CNY = \"CNY\"\n",
    "    HKD = \"HKD\"\n",
    "\n",
    "class OpenExchangeRateApi:\n",
    "    def __init__(self, api_key: str) -> None:\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://openexchangerates.org/api/latest.json\"\n",
    "        self.base_currency = Currency.USD # TODO: not supported in free plan\n",
    "        self.default_exchange_currencies = [\n",
    "            Currency.GBP,\n",
    "            Currency.EUR,\n",
    "            Currency.USD,\n",
    "            Currency.JPY, \n",
    "            Currency.CHF, \n",
    "            Currency.CAD, \n",
    "            Currency.AUD]\n",
    "\n",
    "    def get_latest(self, base_currency: Currency = Currency.GBP, exchangee_currencies: list[Currency] = None ) -> dict:\n",
    "        if exchangee_currencies is None:\n",
    "            exchangee_currencies = self.default_exchange_currencies\n",
    "        params = {\n",
    "            \"app_id\": self.api_key,\n",
    "            # \"base\": self.base_currency, # TODO: not supported in free plan\n",
    "            \"symbols\": \",\".join([currency.value for currency in exchangee_currencies])\n",
    "        }\n",
    "        response = requests.get(self.base_url, params=params)\n",
    "        if response.status_code != 200:\n",
    "            print(response.status_code)\n",
    "            print(response.text)\n",
    "            raise Exception(\"Failed to get jobs\")\n",
    "        return response.json()\n",
    "\n",
    "def oer_load(dict_list: dict) -> pd.DataFrame:\n",
    "    timestamp = dict_list[\"timestamp\"] # UTC timestamp indicating the time the data was collected\n",
    "    pandas_timestamp = pd.Timestamp(timestamp, unit=\"s\")\n",
    "    base_currency = dict_list[\"base\"]\n",
    "    rates = dict_list[\"rates\"]\n",
    "    df = pd.DataFrame.from_dict(rates, orient=\"index\", columns=[\"rate\"])\n",
    "    df[\"timestamp\"] = pandas_timestamp\n",
    "    df[\"base_currency\"] = base_currency\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"index\": \"exchange_currency\"}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting jobs for data science\n",
      "Getting jobs for data science page 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 50 jobs for data science page 0. Total results: 1422\n",
      "Getting jobs for data science page 1\n",
      "Got 50 jobs for data science page 1. Total results: 1422\n",
      "Getting jobs for data science page 2\n",
      "Got 50 jobs for data science page 2. Total results: 1422\n",
      "Got 150 jobs for data science\n",
      "Getting jobs for data engineer\n",
      "Getting jobs for data engineer page 0\n",
      "Got 50 jobs for data engineer page 0. Total results: 3608\n",
      "Getting jobs for data engineer page 1\n",
      "Got 50 jobs for data engineer page 1. Total results: 3608\n",
      "Getting jobs for data engineer page 2\n",
      "Got 50 jobs for data engineer page 2. Total results: 3608\n",
      "Got 150 jobs for data engineer\n",
      "Getting jobs for data analyst\n",
      "Getting jobs for data analyst page 0\n",
      "Got 50 jobs for data analyst page 0. Total results: 3284\n",
      "Getting jobs for data analyst page 1\n",
      "Got 50 jobs for data analyst page 1. Total results: 3284\n",
      "Getting jobs for data analyst page 2\n",
      "Got 50 jobs for data analyst page 2. Total results: 3284\n",
      "Got 150 jobs for data analyst\n",
      "Finished getting jobs\n"
     ]
    }
   ],
   "source": [
    "reed_api = ReedAPI(REED_API_KEY)\n",
    "job_advertisements = dict()\n",
    "for job_title in SAMPLE_JOB_TITLES:\n",
    "    print(f\"Getting jobs for {job_title}\")\n",
    "    advertisements_raw = reed_api.get_all_jobs(job_title)\n",
    "    advertisements_df = reed_load(advertisements_raw)\n",
    "    job_advertisements[job_title] = advertisements_df\n",
    "    print(f\"Got {len(advertisements_df)} jobs for {job_title}\")\n",
    "print(\"Finished getting jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 7 exchange rates\n"
     ]
    }
   ],
   "source": [
    "oer_api = OpenExchangeRateApi(OER_API_KEY)\n",
    "oer_latest_raw = oer_api.get_latest()\n",
    "oer_df = oer_load(oer_latest_raw)\n",
    "print(f\"Got {len(oer_df)} exchange rates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to the database\n"
     ]
    }
   ],
   "source": [
    "test_db_url = URL.create(\n",
    "    drivername=\"postgresql+pg8000\",\n",
    "    username=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT,\n",
    "    database=DB_NAME\n",
    ")\n",
    "\n",
    "engine = create_engine(test_db_url)\n",
    "with engine.connect() as conn:\n",
    "    print(\"Successfully connected to the database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the database tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(engine: Engine, table_name: str, metadata: MetaData, df: pd.DataFrame) -> Table:\n",
    "    # Drop the table if it already exists\n",
    "    if engine.has_table(table_name):\n",
    "        print(f\"Dropping table {table_name}\")\n",
    "        metadata.tables[table_name].drop(engine)\n",
    "        metadata.remove(metadata.tables[table_name])\n",
    "        print(f\"Dropped table {table_name}\")\n",
    "    print(f\"Creating table {table_name}\")\n",
    "\n",
    "    # get the data types for each column\n",
    "    column_types = dict()\n",
    "    for column_name in df.columns:\n",
    "        column_type = df[column_name].dtype\n",
    "        if column_type == \"object\":\n",
    "            column_types[column_name] = String\n",
    "        elif column_type == \"int64\":\n",
    "            column_types[column_name] = Integer\n",
    "        elif column_type == \"float64\":\n",
    "            column_types[column_name] = Float\n",
    "        elif column_type == \"datetime64[ns]\":\n",
    "            column_types[column_name] = DateTime\n",
    "        else:\n",
    "            raise Exception(f\"Unsupported data type {column_type} for column {column_name}\")\n",
    "    \n",
    "    print(f\"Column types: {column_types}\")\n",
    "    # Create the table\n",
    "    table = Table(\n",
    "        table_name,\n",
    "        metadata,\n",
    "        Column(\"id\", Integer, primary_key=True),\n",
    "        *(Column(column_name, column_type) for column_name, column_type in column_types.items())\n",
    "    )\n",
    "    table.create(engine)\n",
    "    print(f\"Created table {table_name}\")\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akoss\\AppData\\Local\\Temp\\ipykernel_21320\\910863053.py:3: SADeprecationWarning: The Engine.has_table() method is deprecated and will be removed in a future release.  Please refer to Inspector.has_table(). (deprecated since: 1.4)\n",
      "  if engine.has_table(table_name):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping table job_advertisements\n",
      "Dropped table job_advertisements\n",
      "Creating table job_advertisements\n",
      "Column types: {'jobId': <class 'sqlalchemy.sql.sqltypes.Integer'>, 'employerId': <class 'sqlalchemy.sql.sqltypes.Integer'>, 'employerName': <class 'sqlalchemy.sql.sqltypes.String'>, 'jobTitle': <class 'sqlalchemy.sql.sqltypes.String'>, 'locationName': <class 'sqlalchemy.sql.sqltypes.String'>, 'minimumSalary': <class 'sqlalchemy.sql.sqltypes.Float'>, 'maximumSalary': <class 'sqlalchemy.sql.sqltypes.Float'>, 'currency': <class 'sqlalchemy.sql.sqltypes.String'>, 'date': <class 'sqlalchemy.sql.sqltypes.DateTime'>, 'applications': <class 'sqlalchemy.sql.sqltypes.Integer'>, 'jobUrl': <class 'sqlalchemy.sql.sqltypes.String'>}\n",
      "Created table job_advertisements\n",
      "Dropping table open_exchange_rates\n",
      "Dropped table open_exchange_rates\n",
      "Creating table open_exchange_rates\n",
      "Column types: {'exchange_currency': <class 'sqlalchemy.sql.sqltypes.String'>, 'rate': <class 'sqlalchemy.sql.sqltypes.Float'>, 'timestamp': <class 'sqlalchemy.sql.sqltypes.DateTime'>, 'base_currency': <class 'sqlalchemy.sql.sqltypes.String'>}\n",
      "Created table open_exchange_rates\n"
     ]
    }
   ],
   "source": [
    "metadata = MetaData(bind=engine)\n",
    "metadata.reflect() # get target table schemas into metadata object \n",
    "job_advertisements_table = create_table(engine, JOB_TABLE_NAME, metadata, list(job_advertisements.values())[0])\n",
    "oer_table = create_table(engine, EXCHANGE_TABLE_NAME, metadata, oer_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating the database with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting data into the job_advertisements table\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\akoss\\work\\learn\\DataCamp\\Project1-Team3\\notebooks\\04_load_sample_data.ipynb Cell 17\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/akoss/work/learn/DataCamp/Project1-Team3/notebooks/04_load_sample_data.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInserting data into the job_advertisements table\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/akoss/work/learn/DataCamp/Project1-Team3/notebooks/04_load_sample_data.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m job_title, job_advertisements_df \u001b[39min\u001b[39;00m job_advertisements\u001b[39m.\u001b[39mitems():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/akoss/work/learn/DataCamp/Project1-Team3/notebooks/04_load_sample_data.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     job_advertisements_df\u001b[39m.\u001b[39;49mto_sql(JOB_TABLE_NAME, engine, if_exists\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mappend\u001b[39;49m\u001b[39m\"\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/akoss/work/learn/DataCamp/Project1-Team3/notebooks/04_load_sample_data.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInserted data into the job_advertisements table\u001b[39m\u001b[39m\"\u001b[39m)    \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/akoss/work/learn/DataCamp/Project1-Team3/notebooks/04_load_sample_data.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInserting data into the open_exchange_rates table\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\site-packages\\pandas\\core\\generic.py:2951\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2794\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2795\u001b[0m \u001b[39mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2796\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2947\u001b[0m \u001b[39m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   2948\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa:E501\u001b[39;00m\n\u001b[0;32m   2949\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m sql\n\u001b[1;32m-> 2951\u001b[0m \u001b[39mreturn\u001b[39;00m sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[0;32m   2952\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2953\u001b[0m     name,\n\u001b[0;32m   2954\u001b[0m     con,\n\u001b[0;32m   2955\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[0;32m   2956\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[0;32m   2957\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   2958\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   2959\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   2960\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   2961\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m   2962\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\site-packages\\pandas\\io\\sql.py:697\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(frame, DataFrame):\n\u001b[0;32m    693\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    694\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument should be either a Series or a DataFrame\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    695\u001b[0m     )\n\u001b[1;32m--> 697\u001b[0m \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39mto_sql(\n\u001b[0;32m    698\u001b[0m     frame,\n\u001b[0;32m    699\u001b[0m     name,\n\u001b[0;32m    700\u001b[0m     if_exists\u001b[39m=\u001b[39mif_exists,\n\u001b[0;32m    701\u001b[0m     index\u001b[39m=\u001b[39mindex,\n\u001b[0;32m    702\u001b[0m     index_label\u001b[39m=\u001b[39mindex_label,\n\u001b[0;32m    703\u001b[0m     schema\u001b[39m=\u001b[39mschema,\n\u001b[0;32m    704\u001b[0m     chunksize\u001b[39m=\u001b[39mchunksize,\n\u001b[0;32m    705\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    706\u001b[0m     method\u001b[39m=\u001b[39mmethod,\n\u001b[0;32m    707\u001b[0m     engine\u001b[39m=\u001b[39mengine,\n\u001b[0;32m    708\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mengine_kwargs,\n\u001b[0;32m    709\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\site-packages\\pandas\\io\\sql.py:1739\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1727\u001b[0m sql_engine \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[0;32m   1729\u001b[0m table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_table(\n\u001b[0;32m   1730\u001b[0m     frame\u001b[39m=\u001b[39mframe,\n\u001b[0;32m   1731\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1736\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   1737\u001b[0m )\n\u001b[1;32m-> 1739\u001b[0m total_inserted \u001b[39m=\u001b[39m sql_engine\u001b[39m.\u001b[39minsert_records(\n\u001b[0;32m   1740\u001b[0m     table\u001b[39m=\u001b[39mtable,\n\u001b[0;32m   1741\u001b[0m     con\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnectable,\n\u001b[0;32m   1742\u001b[0m     frame\u001b[39m=\u001b[39mframe,\n\u001b[0;32m   1743\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[0;32m   1744\u001b[0m     index\u001b[39m=\u001b[39mindex,\n\u001b[0;32m   1745\u001b[0m     schema\u001b[39m=\u001b[39mschema,\n\u001b[0;32m   1746\u001b[0m     chunksize\u001b[39m=\u001b[39mchunksize,\n\u001b[0;32m   1747\u001b[0m     method\u001b[39m=\u001b[39mmethod,\n\u001b[0;32m   1748\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mengine_kwargs,\n\u001b[0;32m   1749\u001b[0m )\n\u001b[0;32m   1751\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_case_sensitive(name\u001b[39m=\u001b[39mname, schema\u001b[39m=\u001b[39mschema)\n\u001b[0;32m   1752\u001b[0m \u001b[39mreturn\u001b[39;00m total_inserted\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\site-packages\\pandas\\io\\sql.py:1322\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[1;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msqlalchemy\u001b[39;00m \u001b[39mimport\u001b[39;00m exc\n\u001b[0;32m   1321\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1322\u001b[0m     \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39;49minsert(chunksize\u001b[39m=\u001b[39;49mchunksize, method\u001b[39m=\u001b[39;49mmethod)\n\u001b[0;32m   1323\u001b[0m \u001b[39mexcept\u001b[39;00m exc\u001b[39m.\u001b[39mSQLAlchemyError \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   1324\u001b[0m     \u001b[39m# GH34431\u001b[39;00m\n\u001b[0;32m   1325\u001b[0m     \u001b[39m# https://stackoverflow.com/a/67358288/6067848\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m(1054, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown column \u001b[39m\u001b[39m'\u001b[39m\u001b[39minf(e0)?\u001b[39m\u001b[39m'\u001b[39m\u001b[39m in \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfield list\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m))(?#\u001b[39m\n\u001b[0;32m   1327\u001b[0m \u001b[39m    )|inf can not be used with MySQL\u001b[39m\u001b[39m\"\"\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\site-packages\\pandas\\io\\sql.py:950\u001b[0m, in \u001b[0;36mSQLTable.insert\u001b[1;34m(self, chunksize, method)\u001b[0m\n\u001b[0;32m    947\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    949\u001b[0m chunk_iter \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m(arr[start_i:end_i] \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m data_list))\n\u001b[1;32m--> 950\u001b[0m num_inserted \u001b[39m=\u001b[39m exec_insert(conn, keys, chunk_iter)\n\u001b[0;32m    951\u001b[0m \u001b[39mif\u001b[39;00m num_inserted \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m     total_inserted \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\site-packages\\pandas\\io\\sql.py:857\u001b[0m, in \u001b[0;36mSQLTable._execute_insert\u001b[1;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    846\u001b[0m \u001b[39mExecute SQL statement inserting data\u001b[39;00m\n\u001b[0;32m    847\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39m   Each item contains a list of values to be inserted\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    856\u001b[0m data \u001b[39m=\u001b[39m [\u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(keys, row)) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m data_iter]\n\u001b[1;32m--> 857\u001b[0m result \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mexecute(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtable\u001b[39m.\u001b[39;49minsert(), data)\n\u001b[0;32m    858\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mrowcount\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1306\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[0;32m   1302\u001b[0m     util\u001b[39m.\u001b[39mraise_(\n\u001b[0;32m   1303\u001b[0m         exc\u001b[39m.\u001b[39mObjectNotExecutableError(statement), replace_context\u001b[39m=\u001b[39merr\n\u001b[0;32m   1304\u001b[0m     )\n\u001b[0;32m   1305\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1306\u001b[0m     \u001b[39mreturn\u001b[39;00m meth(\u001b[39mself\u001b[39;49m, multiparams, params, _EMPTY_EXECUTION_OPTS)\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\site-packages\\sqlalchemy\\sql\\elements.py:332\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, multiparams, params, execution_options, _force)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_execute_on_connection\u001b[39m(\n\u001b[0;32m    329\u001b[0m     \u001b[39mself\u001b[39m, connection, multiparams, params, execution_options, _force\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    330\u001b[0m ):\n\u001b[0;32m    331\u001b[0m     \u001b[39mif\u001b[39;00m _force \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_execution:\n\u001b[1;32m--> 332\u001b[0m         \u001b[39mreturn\u001b[39;00m connection\u001b[39m.\u001b[39;49m_execute_clauseelement(\n\u001b[0;32m    333\u001b[0m             \u001b[39mself\u001b[39;49m, multiparams, params, execution_options\n\u001b[0;32m    334\u001b[0m         )\n\u001b[0;32m    335\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m         \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1498\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, multiparams, params, execution_options)\u001b[0m\n\u001b[0;32m   1486\u001b[0m compiled_cache \u001b[39m=\u001b[39m execution_options\u001b[39m.\u001b[39mget(\n\u001b[0;32m   1487\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcompiled_cache\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_compiled_cache\n\u001b[0;32m   1488\u001b[0m )\n\u001b[0;32m   1490\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_compile_w_cache(\n\u001b[0;32m   1491\u001b[0m     dialect\u001b[39m=\u001b[39mdialect,\n\u001b[0;32m   1492\u001b[0m     compiled_cache\u001b[39m=\u001b[39mcompiled_cache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1496\u001b[0m     linting\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39mcompiler_linting \u001b[39m|\u001b[39m compiler\u001b[39m.\u001b[39mWARN_LINTING,\n\u001b[0;32m   1497\u001b[0m )\n\u001b[1;32m-> 1498\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[0;32m   1499\u001b[0m     dialect,\n\u001b[0;32m   1500\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_compiled,\n\u001b[0;32m   1501\u001b[0m     compiled_sql,\n\u001b[0;32m   1502\u001b[0m     distilled_params,\n\u001b[0;32m   1503\u001b[0m     execution_options,\n\u001b[0;32m   1504\u001b[0m     compiled_sql,\n\u001b[0;32m   1505\u001b[0m     distilled_params,\n\u001b[0;32m   1506\u001b[0m     elem,\n\u001b[0;32m   1507\u001b[0m     extracted_params,\n\u001b[0;32m   1508\u001b[0m     cache_hit\u001b[39m=\u001b[39;49mcache_hit,\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1510\u001b[0m \u001b[39mif\u001b[39;00m has_events:\n\u001b[0;32m   1511\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_execute(\n\u001b[0;32m   1512\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m   1513\u001b[0m         elem,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1517\u001b[0m         ret,\n\u001b[0;32m   1518\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1862\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1859\u001b[0m             branched\u001b[39m.\u001b[39mclose()\n\u001b[0;32m   1861\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 1862\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[0;32m   1863\u001b[0m         e, statement, parameters, cursor, context\n\u001b[0;32m   1864\u001b[0m     )\n\u001b[0;32m   1866\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2047\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[0;32m   2043\u001b[0m         util\u001b[39m.\u001b[39mraise_(\n\u001b[0;32m   2044\u001b[0m             sqlalchemy_exception, with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m], from_\u001b[39m=\u001b[39me\n\u001b[0;32m   2045\u001b[0m         )\n\u001b[0;32m   2046\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2047\u001b[0m         util\u001b[39m.\u001b[39;49mraise_(exc_info[\u001b[39m1\u001b[39;49m], with_traceback\u001b[39m=\u001b[39;49mexc_info[\u001b[39m2\u001b[39;49m])\n\u001b[0;32m   2049\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reentrant_error\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\site-packages\\sqlalchemy\\util\\compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    205\u001b[0m     exception\u001b[39m.\u001b[39m__cause__ \u001b[39m=\u001b[39m replace_context\n\u001b[0;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[0;32m    209\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[39mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1799\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1797\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m   1798\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1799\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_executemany(\n\u001b[0;32m   1800\u001b[0m             cursor, statement, parameters, context\n\u001b[0;32m   1801\u001b[0m         )\n\u001b[0;32m   1802\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameters \u001b[39mand\u001b[39;00m context\u001b[39m.\u001b[39mno_parameters:\n\u001b[0;32m   1803\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\site-packages\\sqlalchemy\\engine\\default.py:729\u001b[0m, in \u001b[0;36mDefaultDialect.do_executemany\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_executemany\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 729\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecutemany(statement, parameters)\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\site-packages\\pg8000\\legacy.py:306\u001b[0m, in \u001b[0;36mCursor.executemany\u001b[1;34m(self, operation, param_sets)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[39mfor\u001b[39;00m parameters \u001b[39min\u001b[39;00m param_sets:\n\u001b[0;32m    305\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_oids \u001b[39m=\u001b[39m input_oids\n\u001b[1;32m--> 306\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(operation, parameters)\n\u001b[0;32m    307\u001b[0m     rowcounts\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context\u001b[39m.\u001b[39mrow_count)\n\u001b[0;32m    309\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(rowcounts) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\site-packages\\pg8000\\legacy.py:254\u001b[0m, in \u001b[0;36mCursor.execute\u001b[1;34m(self, operation, args, stream)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     statement, vals \u001b[39m=\u001b[39m convert_paramstyle(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparamstyle, operation, args)\n\u001b[1;32m--> 254\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_c\u001b[39m.\u001b[39;49mexecute_unnamed(\n\u001b[0;32m    255\u001b[0m         statement, vals\u001b[39m=\u001b[39;49mvals, oids\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_oids, stream\u001b[39m=\u001b[39;49mstream\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    258\u001b[0m rows \u001b[39m=\u001b[39m [] \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context\u001b[39m.\u001b[39mrows \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context\u001b[39m.\u001b[39mrows\n\u001b[0;32m    259\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_row_iter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(rows)\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\site-packages\\pg8000\\core.py:688\u001b[0m, in \u001b[0;36mCoreConnection.execute_unnamed\u001b[1;34m(self, statement, vals, oids, stream)\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_write(SYNC_MSG)\n\u001b[0;32m    687\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flush()\n\u001b[1;32m--> 688\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_messages(context)\n\u001b[0;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m context\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\site-packages\\pg8000\\core.py:806\u001b[0m, in \u001b[0;36mCoreConnection.handle_messages\u001b[1;34m(self, context)\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[39mwhile\u001b[39;00m code \u001b[39m!=\u001b[39m READY_FOR_QUERY:\n\u001b[0;32m    805\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 806\u001b[0m         code, data_len \u001b[39m=\u001b[39m ci_unpack(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read(\u001b[39m5\u001b[39;49m))\n\u001b[0;32m    807\u001b[0m     \u001b[39mexcept\u001b[39;00m struct\u001b[39m.\u001b[39merror \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    808\u001b[0m         \u001b[39mraise\u001b[39;00m InterfaceError(\u001b[39m\"\u001b[39m\u001b[39mnetwork error\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\site-packages\\pg8000\\core.py:287\u001b[0m, in \u001b[0;36mCoreConnection.__init__.<locals>.sock_read\u001b[1;34m(b)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msock_read\u001b[39m(b):\n\u001b[0;32m    286\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 287\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mread(b)\n\u001b[0;32m    288\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    289\u001b[0m         \u001b[39mraise\u001b[39;00m InterfaceError(\u001b[39m\"\u001b[39m\u001b[39mnetwork error\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\akoss\\miniconda3\\envs\\dec_proj1\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Insert the data into the tables\n",
    "print(\"Inserting data into the job_advertisements table\")\n",
    "for job_title, job_advertisements_df in job_advertisements.items():\n",
    "    print(f\"Inserting data for {job_title}\")\n",
    "    job_advertisements_df.to_sql(JOB_TABLE_NAME, engine, if_exists=\"append\", index=False, chunksize=100, method=\"multi\")\n",
    "print(\"Inserted data into the job_advertisements table\")    \n",
    "\n",
    "print(\"Inserting data into the open_exchange_rates table\")\n",
    "oer_df.to_sql(EXCHANGE_TABLE_NAME, engine, if_exists=\"append\", index=False, chunksize=100, method=\"multi\")\n",
    "print(\"Inserted data into the open_exchange_rates table\")\n",
    "\n",
    "# Check the data was inserted correctly\n",
    "print(\"Checking the data was inserted correctly\")\n",
    "verify_df = pd.read_sql_table(JOB_TABLE_NAME, engine)\n",
    "print(verify_df.head())\n",
    "verify_df = pd.read_sql_table(EXCHANGE_TABLE_NAME, engine)\n",
    "print(verify_df.head())\n",
    "print(\"Finished checking the data was inserted correctly\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
